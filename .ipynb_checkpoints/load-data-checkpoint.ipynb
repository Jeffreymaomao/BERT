{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2b77c3ac-060c-4c04-ae8e-aa2baa6669c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import AutoTokenizer, BertForQuestionAnswering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a1235f1-4482-4310-8994-b676d4de7cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_data(path):\n",
    "    with open(path) as f:\n",
    "        json_data = json.load(f)\n",
    "    return json_data[\"data\"]\n",
    "\n",
    "def find_target_sublist(my_list, target_sublist):\n",
    "    target_length = len(target_sublist)\n",
    "    for i in range(len(my_list)):\n",
    "        if my_list[i : i + target_length] == target_sublist:\n",
    "            return i, i + target_length\n",
    "    return -1, -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "357acc89-f9a3-440e-9ecd-bc0e6af5752f",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_datas = load_json_data(\"./dat/train-v2.0.json\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"deepset/bert-base-cased-squad2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "df1c9540-be65-4a27-a73f-aaa726cffe0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = {'input_ids': [],'token_type_ids': [],'attention_mask': [],'start_positions': [],'end_positions': []}\n",
    "\n",
    "impossible_num = 0\n",
    "total_num = 0\n",
    "max_len = 512\n",
    "error_string = []\n",
    "# for json_data in tqdm(json_datas[:1], desc=\"Processing articles\"):\n",
    "for json_data in json_datas[:1]:\n",
    "    for paragraphs in json_data['paragraphs']:\n",
    "        context = paragraphs[\"context\"]\n",
    "        qas = paragraphs['qas']\n",
    "        for qa in qas:\n",
    "            total_num += 1\n",
    "            try:\n",
    "                if not qa['is_impossible']: # 不使用不可能的QA解答\n",
    "                    # 取得問題\n",
    "                    question = qa['question']\n",
    "                    \n",
    "                    # 取得答案\n",
    "                    answers = qa['answers'][0]['text']\n",
    "                    answers_ids = tokenizer(answers).input_ids[1:-1]\n",
    "                    \n",
    "                    # 轉換成數字\n",
    "                    inputs = tokenizer(context, question, return_tensors=\"pt\", max_length=max_len, truncation=True)\n",
    "                    inputs_ids = list(inputs.input_ids[0])\n",
    "\n",
    "                    start_positions, end_positions = find_target_sublist(inputs_ids, answers_ids)\n",
    "                    if start_positions == -1 or end_positions == -1: continue\n",
    "                    start_positions, end_positions = torch.tensor([start_positions]), torch.tensor([end_positions])\n",
    "\n",
    "                    \n",
    "                    input_data['start_positions'].append(start_positions)\n",
    "                    input_data['end_positions'].append(end_positions)\n",
    "                    input_data['input_ids'].append(inputs.input_ids[0])\n",
    "                    input_data['attention_mask'].append(inputs.attention_mask[0])\n",
    "                    input_data['token_type_ids'].append(inputs.token_type_ids[0])\n",
    "                    \n",
    "            except Exception as e:\n",
    "                error_string.append(f\"{e}\")\n",
    "                if not qa[\"is_impossible\"]: \n",
    "                    impossible_num += 1\n",
    "\n",
    "error = list(set([f\"{e}\" for e in error_string]))\n",
    "if(len(error)): print(error)\n",
    "input_data = {k: pad_sequence(v, padding_value=0, batch_first=True) if v else torch.tensor([]) for k, v in input_data.items()}\n",
    "input_data = {k: v[:, :max_len] for k, v in input_data.items() if v.size(0) > 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1fb51ef1-981d-4e13-9c5e-bf98894721b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101, 24041,   144,  ...,     0,     0,     0],\n",
       "        [  101, 24041,   144,  ...,     0,     0,     0],\n",
       "        [  101, 24041,   144,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  1130,  1382,  ...,     0,     0,     0],\n",
       "        [  101,  1130,  1382,  ...,     0,     0,     0],\n",
       "        [  101,  1130,  1382,  ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class QADataset(Dataset):\n",
    "    def __init__(self, input_data):\n",
    "        self.input_data = input_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_data[\"input_ids\"])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.input_data[\"input_ids\"][idx],\n",
    "            \"attention_mask\": self.input_data[\"attention_mask\"][idx],\n",
    "            \"start_positions\": self.input_data[\"start_positions\"][idx],\n",
    "            \"end_positions\": self.input_data[\"end_positions\"][idx],\n",
    "        }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
